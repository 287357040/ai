{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5c7cbc-8d32-4b7a-8dc7-b6a5bc85eb28",
   "metadata": {},
   "source": [
    "# ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61ae1c6-e334-4f3e-aeed-f26b7dea0a30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker>=2.140.0 in /opt/conda/lib/python3.10/site-packages (2.203.0)\n",
      "Requirement already satisfied: transformers==4.26.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.26.1) (4.26.1)\n",
      "Collecting datasets==2.10.1 (from datasets[s3]==2.10.1)\n",
      "  Using cached datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from transformers==4.26.1->transformers[torch]==4.26.1) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (2022.7.9)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.26.1->transformers[torch]==4.26.1) (4.64.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (14.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.10.1->datasets[s3]==2.10.1) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (3.9.1)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1->datasets[s3]==2.10.1) (0.18.0)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.10/site-packages (from datasets[s3]==2.10.1) (0.4.2)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.26.1) (2.1.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (1.33.9)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (4.25.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (4.11.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.7.5)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (4.20.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (2.5.2)\n",
      "Requirement already satisfied: tblib<3,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (1.7.0)\n",
      "Requirement already satisfied: urllib3<1.27 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (1.26.18)\n",
      "Requirement already satisfied: uvicorn==0.22.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.22.0)\n",
      "Requirement already satisfied: fastapi==0.95.2 in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (0.95.2)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (6.1.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker>=2.140.0) (5.9.0)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.95.2->sagemaker>=2.140.0) (1.10.13)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.95.2->sagemaker>=2.140.0) (0.27.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn==0.22.0->sagemaker>=2.140.0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn==0.22.0->sagemaker>=2.140.0) (0.14.0)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.9 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker>=2.140.0) (1.33.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker>=2.140.0) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker>=2.140.0) (0.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->datasets[s3]==2.10.1) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1->transformers[torch]==4.26.1) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker>=2.140.0) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.26.1->transformers[torch]==4.26.1) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->transformers[torch]==4.26.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->transformers[torch]==4.26.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.26.1->transformers[torch]==4.26.1) (2023.11.17)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (12.3.101)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker->sagemaker>=2.140.0) (0.58.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker>=2.140.0) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.140.0) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.140.0) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.140.0) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1->datasets[s3]==2.10.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1->datasets[s3]==2.10.1) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1->datasets[s3]==2.10.1) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker>=2.140.0) (1.7.6.7)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker>=2.140.0) (0.3.3)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker>=2.140.0) (21.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker>=2.140.0) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.7->transformers[torch]==4.26.1) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker>=2.140.0) (1.2.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.16.1\n",
      "    Uninstalling datasets-2.16.1:\n",
      "      Successfully uninstalled datasets-2.16.1\n",
      "Successfully installed datasets-2.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.140.0\" \"transformers[torch]==4.26.1\" \"datasets[s3]==2.10.1\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d894ec0-cc7a-4ff1-951e-8bcefb75bdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::051995725733:role/service-role/AmazonSageMaker-ExecutionRole-20240108T152914\n",
      "sagemaker bucket: sagemaker-us-west-2-051995725733\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4fb18e-978b-498e-a9d8-d4dab431c2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "\n",
    "bucket_name = 'celianih-urbanic'\n",
    "\n",
    "# s3 key prefix for the data\n",
    "s3_prefix = 'datasets/goods'\n",
    "\n",
    "# FeatureExtractor used in preprocessing\n",
    "model_name = 'google/vit-base-patch16-224-in21k'\n",
    "\n",
    "image_processor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a145f2-ce13-4037-9d05-8c637576cbf8",
   "metadata": {},
   "source": [
    "# è®­ç»ƒæ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c83ede4-568b-460a-86be-d5e2bfe6c0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def is_image_file(file_path):\n",
    "    try:\n",
    "        Image.open(file_path)\n",
    "        return True\n",
    "    except (IOError, SyntaxError):\n",
    "        return False\n",
    "    \n",
    "\n",
    "def resize_image(input_path, output_path, target_size=(100, 100)):\n",
    "    with Image.open(input_path) as img:\n",
    "        resized_img = img.resize(target_size)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)  # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹\n",
    "        resized_img.save(output_path)\n",
    "\n",
    "def process_zip(zip_file_path, output_zip_path, target_size=(100, 100)):\n",
    "    with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•ä»¥æå–å›¾åƒ\n",
    "        temp_dir = 'temp_extracted_images'\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "        # ä» ZIP å­˜æ¡£ä¸­æå–æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹\n",
    "        zip_ref.extractall(temp_dir)\n",
    "\n",
    "        # åˆ é™¤ macOS å…ƒæ•°æ®ç›®å½•\n",
    "        macosx_dir = os.path.join(temp_dir, '__MACOSX')\n",
    "        shutil.rmtree(macosx_dir, ignore_errors=True)\n",
    "\n",
    "        # è°ƒæ•´æ¯ä¸ªå›¾åƒçš„å¤§å°å¹¶ä¿å­˜åœ¨è¾“å‡ºç›®å½•ä¸­\n",
    "        resized_images_dir = 'resized_images'\n",
    "        os.makedirs(resized_images_dir, exist_ok=True)\n",
    "\n",
    "        # éå†ä¸´æ—¶ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶\n",
    "        for root, dirs, files in os.walk(temp_dir):\n",
    "            for file_name in files:\n",
    "                input_path = os.path.join(root, file_name)\n",
    "                if is_image_file(input_path):\n",
    "                    output_path = os.path.join(resized_images_dir, os.path.relpath(input_path, temp_dir))\n",
    "                    resize_image(input_path, output_path, target_size)\n",
    "\n",
    "        # ä½¿ç”¨è°ƒæ•´å¤§å°çš„å›¾åƒåˆ›å»ºä¸€ä¸ªæ–°çš„ ZIP æ–‡ä»¶\n",
    "        with ZipFile(output_zip_path, 'w') as new_zip:\n",
    "            for root, dirs, files in os.walk(resized_images_dir):\n",
    "                for file_name in files:\n",
    "                    file_path = os.path.join(root, file_name)\n",
    "                    arcname = os.path.relpath(file_path, resized_images_dir)\n",
    "                    new_zip.write(file_path, arcname=arcname)\n",
    "os.rmdir(temp_dir)\n",
    "# Example usage\n",
    "zip_file_path = './datasets/urbanic.zip'\n",
    "output_zip_path = './datasets/urbanic_small.zip'\n",
    "target_size = (100, 100)\n",
    "\n",
    "process_zip(zip_file_path, output_zip_path, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5d0700-adc8-4128-9e3d-866a006af0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4539386a1e43b3973ab6a077a13fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_result = load_dataset(\"imagefolder\", data_files=\"./datasets/urbanic_small.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bdc4961-7312-4e40-a0af-d69f352995ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900c8cb6ffc74c29b75179eb5d2e19d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Features, Array3D\n",
    "\n",
    "dataset = dataset_result['train']\n",
    "# we need to extend the features \n",
    "features = Features({\n",
    "    **dataset.features,\n",
    "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "})\n",
    "\n",
    "# extractor helper function\n",
    "def preprocess_images(examples):\n",
    "    # get batch of images\n",
    "    images =  examples['image']\n",
    "    inputs = image_processor(images=images)\n",
    "    examples['pixel_values'] = inputs['pixel_values']\n",
    "\n",
    "    return examples\n",
    "\n",
    "# preprocess dataset\n",
    "dataset = dataset.map(preprocess_images, batched=True,features=features)\n",
    "\n",
    "# set to torch format for training\n",
    "dataset.set_format('torch', columns=['pixel_values', 'label'])\n",
    "\n",
    "# remove unused column\n",
    "dataset = dataset.remove_columns(\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb116c9b-db9d-495b-8908-ef5750a8f027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split up training into training + validation\n",
    "splits = dataset.train_test_split(test_size=0.3)\n",
    "train_dataset = splits['train']\n",
    "test_dataset = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c756bb8b-7e93-4457-b470-407c17071e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/fsspec/registry.py:272: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66d0cde47742bcac07c5534bc8b59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597125b6db19450786613e637d7e4f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/131 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset is uploaded to s3://celianih-urbanic/datasets/goods/train\n",
      "test dataset is uploaded to s3://celianih-urbanic/datasets/goods/test\n"
     ]
    }
   ],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{bucket_name}/{s3_prefix}/train'\n",
    "train_dataset.save_to_disk(training_input_path, num_shards=1)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f's3://{bucket_name}/{s3_prefix}/test'\n",
    "test_dataset.save_to_disk(test_input_path, num_shards=1)\n",
    "\n",
    "print(f\"train dataset is uploaded to {training_input_path}\")\n",
    "print(f\"test dataset is uploaded to {test_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17426616-bde6-42ec-9803-42815f1dff5f",
   "metadata": {},
   "source": [
    "# æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e06bd24a-a6d4-4ea9-9b0b-32b6f1d3d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'num_train_epochs': 4, # train epochs\n",
    "                 'per_device_train_batch_size': 3, # batch size\n",
    "                 'model_name': model_name, # model which will be trained on\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81e01dc5-9561-4c70-850b-f415f21f8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir='./scripts',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            transformers_version='4.26',\n",
    "                            pytorch_version='1.13',\n",
    "                            \n",
    "                            py_version='py39',\n",
    "                            hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a97fb97-7c62-46df-981b-39186cad8c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-01-08-13-26-03-732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-08 13:26:04 Starting - Starting the training job......\n",
      "2024-01-08 13:26:38 Starting - Preparing the instances for training...\n",
      "2024-01-08 13:27:32 Downloading - Downloading input data...\n",
      "2024-01-08 13:27:57 Downloading - Downloading the training image.....................\n",
      "2024-01-08 13:31:13 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:29,682 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:29,706 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:29,720 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:29,723 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:30,006 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:30,046 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:30,086 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:30,101 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_name\": \"google/vit-base-patch16-224-in21k\",\n",
      "        \"num_train_epochs\": 4,\n",
      "        \"per_device_train_batch_size\": 3\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-01-08-13-26-03-732\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-051995725733/huggingface-pytorch-training-2024-01-08-13-26-03-732/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_name\":\"google/vit-base-patch16-224-in21k\",\"num_train_epochs\":4,\"per_device_train_batch_size\":3}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-051995725733/huggingface-pytorch-training-2024-01-08-13-26-03-732/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_name\":\"google/vit-base-patch16-224-in21k\",\"num_train_epochs\":4,\"per_device_train_batch_size\":3},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-01-08-13-26-03-732\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-051995725733/huggingface-pytorch-training-2024-01-08-13-26-03-732/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_name\",\"google/vit-base-patch16-224-in21k\",\"--num_train_epochs\",\"4\",\"--per_device_train_batch_size\",\"3\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=google/vit-base-patch16-224-in21k\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=4\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=3\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train.py --model_name google/vit-base-patch16-224-in21k --num_train_epochs 4 --per_device_train_batch_size 3\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:32.361: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:32,369 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:32,400 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:36,117 - __main__ - INFO -  loaded train_dataset length is: 303\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:36,117 - __main__ - INFO -  loaded test_dataset length is: 131\u001b[0m\n",
      "\u001b[34m/opt/ml/code/train.py:73: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(metric_name)\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 4.21kB [00:00, 2.78MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"config.json\";:   0%|          | 0.00/502 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"config.json\";: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 502/502 [00:00<00:00, 62.2kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/346M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:   6%|â–Œ         | 21.0M/346M [00:00<00:01, 177MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  15%|â–ˆâ–Œ        | 52.4M/346M [00:00<00:01, 248MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  24%|â–ˆâ–ˆâ–       | 83.9M/346M [00:00<00:00, 273MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  33%|â–ˆâ–ˆâ–ˆâ–      | 115M/346M [00:00<00:00, 288MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147M/346M [00:00<00:00, 296MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 178M/346M [00:00<00:00, 301MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 210M/346M [00:00<00:00, 304MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 241M/346M [00:00<00:00, 306MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 273M/346M [00:00<00:00, 307MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 304M/346M [00:01<00:00, 306MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 336M/346M [00:01<00:00, 304MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 346M/346M [00:01<00:00, 293MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 303\u001b[0m\n",
      "\u001b[34mNum Epochs = 4\n",
      "  Instantaneous batch size per device = 3\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 3\u001b[0m\n",
      "\u001b[34mTotal train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 404\u001b[0m\n",
      "\u001b[34mTotal train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 404\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 85802501\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 85802501\u001b[0m\n",
      "\u001b[34m0%|          | 0/404 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:41.173: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2024-01-08 13:31:41,179 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:41.221 algo-1:49 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:41.263 algo-1:49 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:41.264 algo-1:49 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:41.264 algo-1:49 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:41.265 algo-1:49 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-01-08 13:31:41.265 algo-1:49 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m0%|          | 1/404 [00:01<12:42,  1.89s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/404 [00:02<05:42,  1.17it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3/404 [00:02<03:27,  1.93it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4/404 [00:02<02:23,  2.78it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 5/404 [00:02<01:48,  3.67it/s]\u001b[0m\n",
      "\u001b[34m1%|â–         | 6/404 [00:02<01:27,  4.55it/s]\u001b[0m\n",
      "\u001b[34m2%|â–         | 7/404 [00:02<01:13,  5.37it/s]\u001b[0m\n",
      "\u001b[34m2%|â–         | 8/404 [00:02<01:05,  6.08it/s]\u001b[0m\n",
      "\u001b[34m2%|â–         | 9/404 [00:02<00:59,  6.62it/s]\u001b[0m\n",
      "\u001b[34m2%|â–         | 10/404 [00:02<00:55,  7.10it/s]\u001b[0m\n",
      "\u001b[34m3%|â–         | 11/404 [00:03<00:53,  7.38it/s]\u001b[0m\n",
      "\u001b[34m3%|â–         | 12/404 [00:03<00:51,  7.54it/s]\u001b[0m\n",
      "\u001b[34m3%|â–         | 13/404 [00:03<00:50,  7.74it/s]\u001b[0m\n",
      "\u001b[34m3%|â–         | 14/404 [00:03<00:50,  7.69it/s]\u001b[0m\n",
      "\u001b[34m4%|â–         | 15/404 [00:03<00:49,  7.87it/s]\u001b[0m\n",
      "\u001b[34m4%|â–         | 16/404 [00:03<00:48,  7.93it/s]\u001b[0m\n",
      "\u001b[34m4%|â–         | 17/404 [00:03<00:49,  7.88it/s]\u001b[0m\n",
      "\u001b[34m4%|â–         | 18/404 [00:03<00:49,  7.85it/s]\u001b[0m\n",
      "\u001b[34m5%|â–         | 19/404 [00:04<00:48,  8.00it/s]\u001b[0m\n",
      "\u001b[34m5%|â–         | 20/404 [00:04<00:48,  7.95it/s]\u001b[0m\n",
      "\u001b[34m5%|â–Œ         | 21/404 [00:04<00:48,  7.91it/s]\u001b[0m\n",
      "\u001b[34m5%|â–Œ         | 22/404 [00:04<00:47,  8.06it/s]\u001b[0m\n",
      "\u001b[34m6%|â–Œ         | 23/404 [00:04<00:47,  8.04it/s]\u001b[0m\n",
      "\u001b[34m6%|â–Œ         | 24/404 [00:04<00:48,  7.78it/s]\u001b[0m\n",
      "\u001b[34m6%|â–Œ         | 25/404 [00:04<00:48,  7.83it/s]\u001b[0m\n",
      "\u001b[34m6%|â–‹         | 26/404 [00:04<00:48,  7.81it/s]\u001b[0m\n",
      "\u001b[34m7%|â–‹         | 27/404 [00:05<00:48,  7.77it/s]\u001b[0m\n",
      "\u001b[34m7%|â–‹         | 28/404 [00:05<00:49,  7.66it/s]\u001b[0m\n",
      "\u001b[34m7%|â–‹         | 29/404 [00:05<00:47,  7.82it/s]\u001b[0m\n",
      "\u001b[34m7%|â–‹         | 30/404 [00:05<00:47,  7.92it/s]\u001b[0m\n",
      "\u001b[34m8%|â–Š         | 31/404 [00:05<00:46,  8.04it/s]\u001b[0m\n",
      "\u001b[34m8%|â–Š         | 32/404 [00:05<00:46,  8.07it/s]\u001b[0m\n",
      "\u001b[34m8%|â–Š         | 33/404 [00:05<00:45,  8.08it/s]\u001b[0m\n",
      "\u001b[34m8%|â–Š         | 34/404 [00:05<00:45,  8.12it/s]\u001b[0m\n",
      "\u001b[34m9%|â–Š         | 35/404 [00:06<00:45,  8.13it/s]\u001b[0m\n",
      "\u001b[34m9%|â–‰         | 36/404 [00:06<00:45,  8.14it/s]\u001b[0m\n",
      "\u001b[34m9%|â–‰         | 37/404 [00:06<00:44,  8.16it/s]\u001b[0m\n",
      "\u001b[34m9%|â–‰         | 38/404 [00:06<00:44,  8.22it/s]\u001b[0m\n",
      "\u001b[34m10%|â–‰         | 39/404 [00:06<00:44,  8.27it/s]\u001b[0m\n",
      "\u001b[34m10%|â–‰         | 40/404 [00:06<00:43,  8.33it/s]\u001b[0m\n",
      "\u001b[34m10%|â–ˆ         | 41/404 [00:06<00:43,  8.36it/s]\u001b[0m\n",
      "\u001b[34m10%|â–ˆ         | 42/404 [00:06<00:43,  8.35it/s]\u001b[0m\n",
      "\u001b[34m11%|â–ˆ         | 43/404 [00:07<00:43,  8.36it/s]\u001b[0m\n",
      "\u001b[34m11%|â–ˆ         | 44/404 [00:07<00:43,  8.37it/s]\u001b[0m\n",
      "\u001b[34m11%|â–ˆ         | 45/404 [00:07<00:42,  8.37it/s]\u001b[0m\n",
      "\u001b[34m11%|â–ˆâ–        | 46/404 [00:07<00:42,  8.39it/s]\u001b[0m\n",
      "\u001b[34m12%|â–ˆâ–        | 47/404 [00:07<00:42,  8.40it/s]\u001b[0m\n",
      "\u001b[34m12%|â–ˆâ–        | 48/404 [00:07<00:42,  8.38it/s]\u001b[0m\n",
      "\u001b[34m12%|â–ˆâ–        | 49/404 [00:07<00:42,  8.37it/s]\u001b[0m\n",
      "\u001b[34m12%|â–ˆâ–        | 50/404 [00:07<00:42,  8.37it/s]\u001b[0m\n",
      "\u001b[34m13%|â–ˆâ–        | 51/404 [00:08<00:42,  8.37it/s]\u001b[0m\n",
      "\u001b[34m13%|â–ˆâ–        | 52/404 [00:08<00:42,  8.37it/s]\u001b[0m\n",
      "\u001b[34m13%|â–ˆâ–        | 53/404 [00:08<00:41,  8.36it/s]\u001b[0m\n",
      "\u001b[34m13%|â–ˆâ–        | 54/404 [00:08<00:42,  8.26it/s]\u001b[0m\n",
      "\u001b[34m14%|â–ˆâ–        | 55/404 [00:08<00:42,  8.31it/s]\u001b[0m\n",
      "\u001b[34m14%|â–ˆâ–        | 56/404 [00:08<00:41,  8.39it/s]\u001b[0m\n",
      "\u001b[34m14%|â–ˆâ–        | 57/404 [00:08<00:41,  8.33it/s]\u001b[0m\n",
      "\u001b[34m14%|â–ˆâ–        | 58/404 [00:08<00:41,  8.37it/s]\u001b[0m\n",
      "\u001b[34m15%|â–ˆâ–        | 59/404 [00:08<00:40,  8.43it/s]\u001b[0m\n",
      "\u001b[34m15%|â–ˆâ–        | 60/404 [00:09<00:40,  8.42it/s]\u001b[0m\n",
      "\u001b[34m15%|â–ˆâ–Œ        | 61/404 [00:09<00:41,  8.26it/s]\u001b[0m\n",
      "\u001b[34m15%|â–ˆâ–Œ        | 62/404 [00:09<00:41,  8.25it/s]\u001b[0m\n",
      "\u001b[34m16%|â–ˆâ–Œ        | 63/404 [00:09<00:41,  8.20it/s]\u001b[0m\n",
      "\u001b[34m16%|â–ˆâ–Œ        | 64/404 [00:09<00:42,  8.00it/s]\u001b[0m\n",
      "\u001b[34m16%|â–ˆâ–Œ        | 65/404 [00:09<00:42,  7.91it/s]\u001b[0m\n",
      "\u001b[34m16%|â–ˆâ–‹        | 66/404 [00:09<00:43,  7.75it/s]\u001b[0m\n",
      "\u001b[34m17%|â–ˆâ–‹        | 67/404 [00:09<00:43,  7.76it/s]\u001b[0m\n",
      "\u001b[34m17%|â–ˆâ–‹        | 68/404 [00:10<00:42,  7.97it/s]\u001b[0m\n",
      "\u001b[34m17%|â–ˆâ–‹        | 69/404 [00:10<00:41,  8.05it/s]\u001b[0m\n",
      "\u001b[34m17%|â–ˆâ–‹        | 70/404 [00:10<00:40,  8.16it/s]\u001b[0m\n",
      "\u001b[34m18%|â–ˆâ–Š        | 71/404 [00:10<00:41,  8.04it/s]\u001b[0m\n",
      "\u001b[34m18%|â–ˆâ–Š        | 72/404 [00:10<00:41,  8.08it/s]\u001b[0m\n",
      "\u001b[34m18%|â–ˆâ–Š        | 73/404 [00:10<00:40,  8.19it/s]\u001b[0m\n",
      "\u001b[34m18%|â–ˆâ–Š        | 74/404 [00:10<00:39,  8.27it/s]\u001b[0m\n",
      "\u001b[34m19%|â–ˆâ–Š        | 75/404 [00:10<00:39,  8.31it/s]\u001b[0m\n",
      "\u001b[34m19%|â–ˆâ–‰        | 76/404 [00:11<00:40,  8.03it/s]\u001b[0m\n",
      "\u001b[34m19%|â–ˆâ–‰        | 77/404 [00:11<00:40,  7.99it/s]\u001b[0m\n",
      "\u001b[34m19%|â–ˆâ–‰        | 78/404 [00:11<00:40,  8.02it/s]\u001b[0m\n",
      "\u001b[34m20%|â–ˆâ–‰        | 79/404 [00:11<00:40,  8.01it/s]\u001b[0m\n",
      "\u001b[34m20%|â–ˆâ–‰        | 80/404 [00:11<00:41,  7.84it/s]\u001b[0m\n",
      "\u001b[34m20%|â–ˆâ–ˆ        | 81/404 [00:11<00:40,  7.91it/s]\u001b[0m\n",
      "\u001b[34m20%|â–ˆâ–ˆ        | 82/404 [00:11<00:41,  7.76it/s]\u001b[0m\n",
      "\u001b[34m21%|â–ˆâ–ˆ        | 83/404 [00:11<00:41,  7.72it/s]\u001b[0m\n",
      "\u001b[34m21%|â–ˆâ–ˆ        | 84/404 [00:12<00:41,  7.66it/s]\u001b[0m\n",
      "\u001b[34m21%|â–ˆâ–ˆ        | 85/404 [00:12<00:40,  7.88it/s]\u001b[0m\n",
      "\u001b[34m21%|â–ˆâ–ˆâ–       | 86/404 [00:12<00:39,  8.02it/s]\u001b[0m\n",
      "\u001b[34m22%|â–ˆâ–ˆâ–       | 87/404 [00:12<00:39,  7.97it/s]\u001b[0m\n",
      "\u001b[34m22%|â–ˆâ–ˆâ–       | 88/404 [00:12<00:39,  7.97it/s]\u001b[0m\n",
      "\u001b[34m22%|â–ˆâ–ˆâ–       | 89/404 [00:12<00:38,  8.13it/s]\u001b[0m\n",
      "\u001b[34m22%|â–ˆâ–ˆâ–       | 90/404 [00:12<00:38,  8.25it/s]\u001b[0m\n",
      "\u001b[34m23%|â–ˆâ–ˆâ–       | 91/404 [00:12<00:37,  8.26it/s]\u001b[0m\n",
      "\u001b[34m23%|â–ˆâ–ˆâ–       | 92/404 [00:13<00:37,  8.31it/s]\u001b[0m\n",
      "\u001b[34m23%|â–ˆâ–ˆâ–       | 93/404 [00:13<00:38,  8.08it/s]\u001b[0m\n",
      "\u001b[34m23%|â–ˆâ–ˆâ–       | 94/404 [00:13<00:38,  8.04it/s]\u001b[0m\n",
      "\u001b[34m24%|â–ˆâ–ˆâ–       | 95/404 [00:13<00:38,  8.03it/s]\u001b[0m\n",
      "\u001b[34m24%|â–ˆâ–ˆâ–       | 96/404 [00:13<00:38,  7.96it/s]\u001b[0m\n",
      "\u001b[34m24%|â–ˆâ–ˆâ–       | 97/404 [00:13<00:38,  7.96it/s]\u001b[0m\n",
      "\u001b[34m24%|â–ˆâ–ˆâ–       | 98/404 [00:13<00:39,  7.84it/s]\u001b[0m\n",
      "\u001b[34m25%|â–ˆâ–ˆâ–       | 99/404 [00:13<00:38,  7.98it/s]\u001b[0m\n",
      "\u001b[34m25%|â–ˆâ–ˆâ–       | 100/404 [00:14<00:38,  7.92it/s]\u001b[0m\n",
      "\u001b[34m25%|â–ˆâ–ˆâ–Œ       | 101/404 [00:14<00:38,  7.81it/s]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.461093544960022, 'eval_accuracy': 0.5190839694656488, 'eval_runtime': 2.5555, 'eval_samples_per_second': 51.261, 'eval_steps_per_second': 1.174, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m25%|â–ˆâ–ˆâ–Œ       | 101/404 [00:16<00:38,  7.81it/s]\u001b[0m\n",
      "\u001b[34m#015100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-101\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-101\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-101/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-101/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-101/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-101/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m25%|â–ˆâ–ˆâ–Œ       | 102/404 [00:18<06:35,  1.31s/it]\u001b[0m\n",
      "\u001b[34m25%|â–ˆâ–ˆâ–Œ       | 103/404 [00:18<04:46,  1.05it/s]\u001b[0m\n",
      "\u001b[34m26%|â–ˆâ–ˆâ–Œ       | 104/404 [00:18<03:31,  1.42it/s]\u001b[0m\n",
      "\u001b[34m26%|â–ˆâ–ˆâ–Œ       | 105/404 [00:18<02:38,  1.88it/s]\u001b[0m\n",
      "\u001b[34m26%|â–ˆâ–ˆâ–Œ       | 106/404 [00:18<02:01,  2.46it/s]\u001b[0m\n",
      "\u001b[34m26%|â–ˆâ–ˆâ–‹       | 107/404 [00:18<01:35,  3.12it/s]\u001b[0m\n",
      "\u001b[34m27%|â–ˆâ–ˆâ–‹       | 108/404 [00:19<01:17,  3.83it/s]\u001b[0m\n",
      "\u001b[34m27%|â–ˆâ–ˆâ–‹       | 109/404 [00:19<01:05,  4.49it/s]\u001b[0m\n",
      "\u001b[34m27%|â–ˆâ–ˆâ–‹       | 110/404 [00:19<00:56,  5.18it/s]\u001b[0m\n",
      "\u001b[34m27%|â–ˆâ–ˆâ–‹       | 111/404 [00:19<00:50,  5.79it/s]\u001b[0m\n",
      "\u001b[34m28%|â–ˆâ–ˆâ–Š       | 112/404 [00:19<00:45,  6.36it/s]\u001b[0m\n",
      "\u001b[34m28%|â–ˆâ–ˆâ–Š       | 113/404 [00:19<00:43,  6.76it/s]\u001b[0m\n",
      "\u001b[34m28%|â–ˆâ–ˆâ–Š       | 114/404 [00:19<00:40,  7.21it/s]\u001b[0m\n",
      "\u001b[34m28%|â–ˆâ–ˆâ–Š       | 115/404 [00:19<00:38,  7.56it/s]\u001b[0m\n",
      "\u001b[34m29%|â–ˆâ–ˆâ–Š       | 116/404 [00:20<00:37,  7.73it/s]\u001b[0m\n",
      "\u001b[34m29%|â–ˆâ–ˆâ–‰       | 117/404 [00:20<00:36,  7.95it/s]\u001b[0m\n",
      "\u001b[34m29%|â–ˆâ–ˆâ–‰       | 118/404 [00:20<00:36,  7.85it/s]\u001b[0m\n",
      "\u001b[34m29%|â–ˆâ–ˆâ–‰       | 119/404 [00:20<00:36,  7.90it/s]\u001b[0m\n",
      "\u001b[34m30%|â–ˆâ–ˆâ–‰       | 120/404 [00:20<00:35,  7.93it/s]\u001b[0m\n",
      "\u001b[34m30%|â–ˆâ–ˆâ–‰       | 121/404 [00:20<00:35,  8.02it/s]\u001b[0m\n",
      "\u001b[34m30%|â–ˆâ–ˆâ–ˆ       | 122/404 [00:20<00:34,  8.08it/s]\u001b[0m\n",
      "\u001b[34m30%|â–ˆâ–ˆâ–ˆ       | 123/404 [00:20<00:35,  8.01it/s]\u001b[0m\n",
      "\u001b[34m31%|â–ˆâ–ˆâ–ˆ       | 124/404 [00:21<00:35,  7.98it/s]\u001b[0m\n",
      "\u001b[34m31%|â–ˆâ–ˆâ–ˆ       | 125/404 [00:21<00:35,  7.79it/s]\u001b[0m\n",
      "\u001b[34m31%|â–ˆâ–ˆâ–ˆ       | 126/404 [00:21<00:35,  7.73it/s]\u001b[0m\n",
      "\u001b[34m31%|â–ˆâ–ˆâ–ˆâ–      | 127/404 [00:21<00:36,  7.62it/s]\u001b[0m\n",
      "\u001b[34m32%|â–ˆâ–ˆâ–ˆâ–      | 128/404 [00:21<00:37,  7.37it/s]\u001b[0m\n",
      "\u001b[34m32%|â–ˆâ–ˆâ–ˆâ–      | 129/404 [00:21<00:37,  7.24it/s]\u001b[0m\n",
      "\u001b[34m32%|â–ˆâ–ˆâ–ˆâ–      | 130/404 [00:21<00:36,  7.50it/s]\u001b[0m\n",
      "\u001b[34m32%|â–ˆâ–ˆâ–ˆâ–      | 131/404 [00:21<00:36,  7.40it/s]\u001b[0m\n",
      "\u001b[34m33%|â–ˆâ–ˆâ–ˆâ–      | 132/404 [00:22<00:36,  7.36it/s]\u001b[0m\n",
      "\u001b[34m33%|â–ˆâ–ˆâ–ˆâ–      | 133/404 [00:22<00:36,  7.45it/s]\u001b[0m\n",
      "\u001b[34m33%|â–ˆâ–ˆâ–ˆâ–      | 134/404 [00:22<00:35,  7.54it/s]\u001b[0m\n",
      "\u001b[34m33%|â–ˆâ–ˆâ–ˆâ–      | 135/404 [00:22<00:35,  7.63it/s]\u001b[0m\n",
      "\u001b[34m34%|â–ˆâ–ˆâ–ˆâ–      | 136/404 [00:22<00:34,  7.67it/s]\u001b[0m\n",
      "\u001b[34m34%|â–ˆâ–ˆâ–ˆâ–      | 137/404 [00:22<00:34,  7.64it/s]\u001b[0m\n",
      "\u001b[34m34%|â–ˆâ–ˆâ–ˆâ–      | 138/404 [00:22<00:34,  7.75it/s]\u001b[0m\n",
      "\u001b[34m34%|â–ˆâ–ˆâ–ˆâ–      | 139/404 [00:22<00:33,  7.92it/s]\u001b[0m\n",
      "\u001b[34m35%|â–ˆâ–ˆâ–ˆâ–      | 140/404 [00:23<00:33,  7.89it/s]\u001b[0m\n",
      "\u001b[34m35%|â–ˆâ–ˆâ–ˆâ–      | 141/404 [00:23<00:33,  7.82it/s]\u001b[0m\n",
      "\u001b[34m35%|â–ˆâ–ˆâ–ˆâ–Œ      | 142/404 [00:23<00:33,  7.81it/s]\u001b[0m\n",
      "\u001b[34m35%|â–ˆâ–ˆâ–ˆâ–Œ      | 143/404 [00:23<00:33,  7.90it/s]\u001b[0m\n",
      "\u001b[34m36%|â–ˆâ–ˆâ–ˆâ–Œ      | 144/404 [00:23<00:32,  8.04it/s]\u001b[0m\n",
      "\u001b[34m36%|â–ˆâ–ˆâ–ˆâ–Œ      | 145/404 [00:23<00:31,  8.10it/s]\u001b[0m\n",
      "\u001b[34m36%|â–ˆâ–ˆâ–ˆâ–Œ      | 146/404 [00:23<00:31,  8.11it/s]\u001b[0m\n",
      "\u001b[34m36%|â–ˆâ–ˆâ–ˆâ–‹      | 147/404 [00:23<00:31,  8.11it/s]\u001b[0m\n",
      "\u001b[34m37%|â–ˆâ–ˆâ–ˆâ–‹      | 148/404 [00:24<00:31,  8.16it/s]\u001b[0m\n",
      "\u001b[34m37%|â–ˆâ–ˆâ–ˆâ–‹      | 149/404 [00:24<00:30,  8.27it/s]\u001b[0m\n",
      "\u001b[34m37%|â–ˆâ–ˆâ–ˆâ–‹      | 150/404 [00:24<00:30,  8.35it/s]\u001b[0m\n",
      "\u001b[34m37%|â–ˆâ–ˆâ–ˆâ–‹      | 151/404 [00:24<00:30,  8.27it/s]\u001b[0m\n",
      "\u001b[34m38%|â–ˆâ–ˆâ–ˆâ–Š      | 152/404 [00:24<00:31,  8.04it/s]\u001b[0m\n",
      "\u001b[34m38%|â–ˆâ–ˆâ–ˆâ–Š      | 153/404 [00:24<00:30,  8.15it/s]\u001b[0m\n",
      "\u001b[34m38%|â–ˆâ–ˆâ–ˆâ–Š      | 154/404 [00:24<00:31,  8.04it/s]\u001b[0m\n",
      "\u001b[34m38%|â–ˆâ–ˆâ–ˆâ–Š      | 155/404 [00:24<00:30,  8.18it/s]\u001b[0m\n",
      "\u001b[34m39%|â–ˆâ–ˆâ–ˆâ–Š      | 156/404 [00:25<00:30,  8.09it/s]\u001b[0m\n",
      "\u001b[34m39%|â–ˆâ–ˆâ–ˆâ–‰      | 157/404 [00:25<00:30,  8.11it/s]\u001b[0m\n",
      "\u001b[34m39%|â–ˆâ–ˆâ–ˆâ–‰      | 158/404 [00:25<00:30,  8.10it/s]\u001b[0m\n",
      "\u001b[34m39%|â–ˆâ–ˆâ–ˆâ–‰      | 159/404 [00:25<00:30,  7.97it/s]\u001b[0m\n",
      "\u001b[34m40%|â–ˆâ–ˆâ–ˆâ–‰      | 160/404 [00:25<00:31,  7.86it/s]\u001b[0m\n",
      "\u001b[34m40%|â–ˆâ–ˆâ–ˆâ–‰      | 161/404 [00:25<00:31,  7.80it/s]\u001b[0m\n",
      "\u001b[34m40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 162/404 [00:25<00:31,  7.72it/s]\u001b[0m\n",
      "\u001b[34m40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 163/404 [00:25<00:30,  7.84it/s]\u001b[0m\n",
      "\u001b[34m41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 164/404 [00:26<00:30,  7.92it/s]\u001b[0m\n",
      "\u001b[34m41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 165/404 [00:26<00:29,  8.01it/s]\u001b[0m\n",
      "\u001b[34m41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 166/404 [00:26<00:29,  8.16it/s]\u001b[0m\n",
      "\u001b[34m41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 167/404 [00:26<00:28,  8.25it/s]\u001b[0m\n",
      "\u001b[34m42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 168/404 [00:26<00:28,  8.20it/s]\u001b[0m\n",
      "\u001b[34m42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 169/404 [00:26<00:29,  7.96it/s]\u001b[0m\n",
      "\u001b[34m42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 170/404 [00:26<00:29,  8.01it/s]\u001b[0m\n",
      "\u001b[34m42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 171/404 [00:26<00:29,  7.89it/s]\u001b[0m\n",
      "\u001b[34m43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 172/404 [00:27<00:29,  7.96it/s]\u001b[0m\n",
      "\u001b[34m43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 173/404 [00:27<00:29,  7.95it/s]\u001b[0m\n",
      "\u001b[34m43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 174/404 [00:27<00:29,  7.80it/s]\u001b[0m\n",
      "\u001b[34m43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 175/404 [00:27<00:29,  7.80it/s]\u001b[0m\n",
      "\u001b[34m44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 176/404 [00:27<00:29,  7.70it/s]\u001b[0m\n",
      "\u001b[34m44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 177/404 [00:27<00:29,  7.68it/s]\u001b[0m\n",
      "\u001b[34m44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 178/404 [00:27<00:29,  7.73it/s]\u001b[0m\n",
      "\u001b[34m44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 179/404 [00:28<00:28,  7.87it/s]\u001b[0m\n",
      "\u001b[34m45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 180/404 [00:28<00:28,  7.97it/s]\u001b[0m\n",
      "\u001b[34m45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 181/404 [00:28<00:27,  8.05it/s]\u001b[0m\n",
      "\u001b[34m45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 182/404 [00:28<00:27,  8.13it/s]\u001b[0m\n",
      "\u001b[34m45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 183/404 [00:28<00:27,  8.14it/s]\u001b[0m\n",
      "\u001b[34m46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 184/404 [00:28<00:26,  8.18it/s]\u001b[0m\n",
      "\u001b[34m46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 185/404 [00:28<00:26,  8.21it/s]\u001b[0m\n",
      "\u001b[34m46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 186/404 [00:28<00:26,  8.22it/s]\u001b[0m\n",
      "\u001b[34m46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 187/404 [00:28<00:26,  8.05it/s]\u001b[0m\n",
      "\u001b[34m47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 188/404 [00:29<00:27,  7.95it/s]\u001b[0m\n",
      "\u001b[34m47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 189/404 [00:29<00:26,  8.04it/s]\u001b[0m\n",
      "\u001b[34m47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 190/404 [00:29<00:26,  8.16it/s]\u001b[0m\n",
      "\u001b[34m47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 191/404 [00:29<00:26,  8.19it/s]\u001b[0m\n",
      "\u001b[34m48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 192/404 [00:29<00:25,  8.17it/s]\u001b[0m\n",
      "\u001b[34m48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 193/404 [00:29<00:25,  8.13it/s]\u001b[0m\n",
      "\u001b[34m48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 194/404 [00:29<00:26,  7.99it/s]\u001b[0m\n",
      "\u001b[34m48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 195/404 [00:29<00:26,  7.85it/s]\u001b[0m\n",
      "\u001b[34m49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 196/404 [00:30<00:26,  7.85it/s]\u001b[0m\n",
      "\u001b[34m49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 197/404 [00:30<00:25,  8.03it/s]\u001b[0m\n",
      "\u001b[34m49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 198/404 [00:30<00:25,  8.14it/s]\u001b[0m\n",
      "\u001b[34m49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 199/404 [00:30<00:24,  8.26it/s]\u001b[0m\n",
      "\u001b[34m50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 200/404 [00:30<00:25,  8.14it/s]\u001b[0m\n",
      "\u001b[34m50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 201/404 [00:30<00:25,  8.09it/s]\u001b[0m\n",
      "\u001b[34m50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 202/404 [00:30<00:24,  8.14it/s]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.946310818195343, 'eval_accuracy': 0.8091603053435115, 'eval_runtime': 2.3675, 'eval_samples_per_second': 55.333, 'eval_steps_per_second': 1.267, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 202/404 [00:33<00:24,  8.14it/s]\u001b[0m\n",
      "\u001b[34m#015100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                             #033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-202\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-202\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-202/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-202/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-202/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-202/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 203/404 [00:34<04:09,  1.24s/it]\u001b[0m\n",
      "\u001b[34m50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 204/404 [00:34<03:01,  1.10it/s]\u001b[0m\n",
      "\u001b[34m51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 205/404 [00:34<02:13,  1.49it/s]\u001b[0m\n",
      "\u001b[34m51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 206/404 [00:35<01:40,  1.96it/s]\u001b[0m\n",
      "\u001b[34m51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 207/404 [00:35<01:17,  2.54it/s]\u001b[0m\n",
      "\u001b[34m51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 208/404 [00:35<01:01,  3.19it/s]\u001b[0m\n",
      "\u001b[34m52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 209/404 [00:35<00:50,  3.88it/s]\u001b[0m\n",
      "\u001b[34m52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 210/404 [00:35<00:42,  4.58it/s]\u001b[0m\n",
      "\u001b[34m52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 211/404 [00:35<00:36,  5.29it/s]\u001b[0m\n",
      "\u001b[34m52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 212/404 [00:35<00:32,  5.97it/s]\u001b[0m\n",
      "\u001b[34m53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 213/404 [00:35<00:29,  6.56it/s]\u001b[0m\n",
      "\u001b[34m53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 214/404 [00:36<00:26,  7.05it/s]\u001b[0m\n",
      "\u001b[34m53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 215/404 [00:36<00:25,  7.36it/s]\u001b[0m\n",
      "\u001b[34m53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 216/404 [00:36<00:24,  7.68it/s]\u001b[0m\n",
      "\u001b[34m54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 217/404 [00:36<00:23,  7.93it/s]\u001b[0m\n",
      "\u001b[34m54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 218/404 [00:36<00:23,  8.05it/s]\u001b[0m\n",
      "\u001b[34m54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 219/404 [00:36<00:22,  8.08it/s]\u001b[0m\n",
      "\u001b[34m54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 220/404 [00:36<00:22,  8.06it/s]\u001b[0m\n",
      "\u001b[34m55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 221/404 [00:36<00:22,  8.10it/s]\u001b[0m\n",
      "\u001b[34m55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 222/404 [00:37<00:22,  8.11it/s]\u001b[0m\n",
      "\u001b[34m55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 223/404 [00:37<00:22,  8.19it/s]\u001b[0m\n",
      "\u001b[34m55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 224/404 [00:37<00:22,  8.10it/s]\u001b[0m\n",
      "\u001b[34m56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 225/404 [00:37<00:22,  8.13it/s]\u001b[0m\n",
      "\u001b[34m56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 226/404 [00:37<00:21,  8.10it/s]\u001b[0m\n",
      "\u001b[34m56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 227/404 [00:37<00:21,  8.14it/s]\u001b[0m\n",
      "\u001b[34m56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 228/404 [00:37<00:21,  8.17it/s]\u001b[0m\n",
      "\u001b[34m57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 229/404 [00:37<00:21,  8.20it/s]\u001b[0m\n",
      "\u001b[34m57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 230/404 [00:37<00:21,  8.21it/s]\u001b[0m\n",
      "\u001b[34m57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 231/404 [00:38<00:21,  8.22it/s]\u001b[0m\n",
      "\u001b[34m57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 232/404 [00:38<00:21,  8.08it/s]\u001b[0m\n",
      "\u001b[34m58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 233/404 [00:38<00:21,  8.10it/s]\u001b[0m\n",
      "\u001b[34m58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 234/404 [00:38<00:21,  7.94it/s]\u001b[0m\n",
      "\u001b[34m58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 235/404 [00:38<00:21,  7.92it/s]\u001b[0m\n",
      "\u001b[34m58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 236/404 [00:38<00:20,  8.03it/s]\u001b[0m\n",
      "\u001b[34m59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 237/404 [00:38<00:20,  8.09it/s]\u001b[0m\n",
      "\u001b[34m59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 238/404 [00:38<00:20,  8.13it/s]\u001b[0m\n",
      "\u001b[34m59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 239/404 [00:39<00:20,  8.16it/s]\u001b[0m\n",
      "\u001b[34m59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 240/404 [00:39<00:20,  8.08it/s]\u001b[0m\n",
      "\u001b[34m60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 241/404 [00:39<00:20,  8.12it/s]\u001b[0m\n",
      "\u001b[34m60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 242/404 [00:39<00:19,  8.15it/s]\u001b[0m\n",
      "\u001b[34m60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 243/404 [00:39<00:19,  8.22it/s]\u001b[0m\n",
      "\u001b[34m60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 244/404 [00:39<00:19,  8.16it/s]\u001b[0m\n",
      "\u001b[34m61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 245/404 [00:39<00:19,  8.22it/s]\u001b[0m\n",
      "\u001b[34m61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 246/404 [00:39<00:19,  8.26it/s]\u001b[0m\n",
      "\u001b[34m61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 247/404 [00:40<00:18,  8.28it/s]\u001b[0m\n",
      "\u001b[34m61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 248/404 [00:40<00:19,  8.16it/s]\u001b[0m\n",
      "\u001b[34m62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 249/404 [00:40<00:19,  7.90it/s]\u001b[0m\n",
      "\u001b[34m62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 250/404 [00:40<00:19,  7.81it/s]\u001b[0m\n",
      "\u001b[34m62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 251/404 [00:40<00:19,  7.74it/s]\u001b[0m\n",
      "\u001b[34m62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 252/404 [00:40<00:19,  7.94it/s]\u001b[0m\n",
      "\u001b[34m63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 253/404 [00:40<00:18,  8.08it/s]\u001b[0m\n",
      "\u001b[34m63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 254/404 [00:40<00:18,  8.16it/s]\u001b[0m\n",
      "\u001b[34m63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 255/404 [00:41<00:18,  8.21it/s]\u001b[0m\n",
      "\u001b[34m63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 256/404 [00:41<00:18,  8.20it/s]\u001b[0m\n",
      "\u001b[34m64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 257/404 [00:41<00:17,  8.25it/s]\u001b[0m\n",
      "\u001b[34m64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 258/404 [00:41<00:17,  8.27it/s]\u001b[0m\n",
      "\u001b[34m64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 259/404 [00:41<00:17,  8.30it/s]\u001b[0m\n",
      "\u001b[34m64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 260/404 [00:41<00:17,  8.34it/s]\u001b[0m\n",
      "\u001b[34m65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 261/404 [00:41<00:17,  8.32it/s]\u001b[0m\n",
      "\u001b[34m65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 262/404 [00:41<00:17,  8.35it/s]\u001b[0m\n",
      "\u001b[34m65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 263/404 [00:42<00:17,  8.25it/s]\u001b[0m\n",
      "\u001b[34m65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 264/404 [00:42<00:16,  8.31it/s]\u001b[0m\n",
      "\u001b[34m66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 265/404 [00:42<00:16,  8.30it/s]\u001b[0m\n",
      "\u001b[34m66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 266/404 [00:42<00:16,  8.34it/s]\u001b[0m\n",
      "\u001b[34m66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 267/404 [00:42<00:16,  8.36it/s]\u001b[0m\n",
      "\u001b[34m66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 268/404 [00:42<00:16,  8.40it/s]\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 269/404 [00:42<00:15,  8.44it/s]\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 270/404 [00:42<00:15,  8.48it/s]\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 271/404 [00:42<00:15,  8.38it/s]\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 272/404 [00:43<00:16,  8.25it/s]\u001b[0m\n",
      "\u001b[34m68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 273/404 [00:43<00:16,  8.05it/s]\u001b[0m\n",
      "\u001b[34m68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 274/404 [00:43<00:15,  8.20it/s]\u001b[0m\n",
      "\u001b[34m68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 275/404 [00:43<00:15,  8.30it/s]\u001b[0m\n",
      "\u001b[34m68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 276/404 [00:43<00:15,  8.36it/s]\u001b[0m\n",
      "\u001b[34m69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 277/404 [00:43<00:15,  8.32it/s]\u001b[0m\n",
      "\u001b[34m69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 278/404 [00:43<00:15,  8.32it/s]\u001b[0m\n",
      "\u001b[34m69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 279/404 [00:43<00:15,  8.27it/s]\u001b[0m\n",
      "\u001b[34m69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 280/404 [00:44<00:14,  8.35it/s]\u001b[0m\n",
      "\u001b[34m70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 281/404 [00:44<00:14,  8.33it/s]\u001b[0m\n",
      "\u001b[34m70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 282/404 [00:44<00:14,  8.22it/s]\u001b[0m\n",
      "\u001b[34m70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 283/404 [00:44<00:14,  8.16it/s]\u001b[0m\n",
      "\u001b[34m70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 284/404 [00:44<00:14,  8.05it/s]\u001b[0m\n",
      "\u001b[34m71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 285/404 [00:44<00:14,  8.07it/s]\u001b[0m\n",
      "\u001b[34m71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 286/404 [00:44<00:14,  8.11it/s]\u001b[0m\n",
      "\u001b[34m71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 287/404 [00:44<00:14,  8.20it/s]\u001b[0m\n",
      "\u001b[34m71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 288/404 [00:45<00:14,  8.20it/s]\u001b[0m\n",
      "\u001b[34m72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 289/404 [00:45<00:13,  8.25it/s]\u001b[0m\n",
      "\u001b[34m72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 290/404 [00:45<00:13,  8.17it/s]\u001b[0m\n",
      "\u001b[34m72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 291/404 [00:45<00:13,  8.24it/s]\u001b[0m\n",
      "\u001b[34m72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 292/404 [00:45<00:13,  8.15it/s]\u001b[0m\n",
      "\u001b[34m73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 293/404 [00:45<00:13,  8.05it/s]\u001b[0m\n",
      "\u001b[34m73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 294/404 [00:45<00:13,  8.09it/s]\u001b[0m\n",
      "\u001b[34m73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 295/404 [00:45<00:13,  8.17it/s]\u001b[0m\n",
      "\u001b[34m73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 296/404 [00:46<00:13,  8.23it/s]\u001b[0m\n",
      "\u001b[34m74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 297/404 [00:46<00:12,  8.29it/s]\u001b[0m\n",
      "\u001b[34m74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 298/404 [00:46<00:12,  8.34it/s]\u001b[0m\n",
      "\u001b[34m74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 299/404 [00:46<00:12,  8.35it/s]\u001b[0m\n",
      "\u001b[34m74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 300/404 [00:46<00:12,  8.35it/s]\u001b[0m\n",
      "\u001b[34m75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 301/404 [00:46<00:12,  8.27it/s]\u001b[0m\n",
      "\u001b[34m75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 302/404 [00:46<00:12,  8.32it/s]\u001b[0m\n",
      "\u001b[34m75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 303/404 [00:46<00:12,  8.29it/s]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 131\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mBatch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5382120609283447, 'eval_accuracy': 0.816793893129771, 'eval_runtime': 2.346, 'eval_samples_per_second': 55.839, 'eval_steps_per_second': 1.279, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 303/404 [00:49<00:12,  8.29it/s]\u001b[0m\n",
      "\u001b[34m#015100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                             #033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-303\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-303\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-303/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-303/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-303/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-303/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 304/404 [00:50<02:03,  1.24s/it]\u001b[0m\n",
      "\u001b[34m75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 305/404 [00:50<01:29,  1.11it/s]\u001b[0m\n",
      "\u001b[34m76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 306/404 [00:50<01:05,  1.49it/s]\u001b[0m\n",
      "\u001b[34m76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 307/404 [00:51<00:49,  1.98it/s]\u001b[0m\n",
      "\u001b[34m76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 308/404 [00:51<00:37,  2.55it/s]\u001b[0m\n",
      "\u001b[34m76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 309/404 [00:51<00:29,  3.21it/s]\u001b[0m\n",
      "\u001b[34m77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 310/404 [00:51<00:23,  3.94it/s]\u001b[0m\n",
      "\u001b[34m77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 311/404 [00:51<00:19,  4.71it/s]\u001b[0m\n",
      "\u001b[34m77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 312/404 [00:51<00:17,  5.38it/s]\u001b[0m\n",
      "\u001b[34m77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 313/404 [00:51<00:15,  6.04it/s]\u001b[0m\n",
      "\u001b[34m78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 314/404 [00:51<00:13,  6.64it/s]\u001b[0m\n",
      "\u001b[34m78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 315/404 [00:52<00:12,  7.09it/s]\u001b[0m\n",
      "\u001b[34m78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 316/404 [00:52<00:11,  7.40it/s]\u001b[0m\n",
      "\u001b[34m78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 317/404 [00:52<00:11,  7.67it/s]\u001b[0m\n",
      "\u001b[34m79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 318/404 [00:52<00:10,  7.89it/s]\u001b[0m\n",
      "\u001b[34m79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 319/404 [00:52<00:10,  8.05it/s]\u001b[0m\n",
      "\u001b[34m79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 320/404 [00:52<00:10,  8.16it/s]\u001b[0m\n",
      "\u001b[34m79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 321/404 [00:52<00:10,  8.25it/s]\u001b[0m\n",
      "\u001b[34m80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 322/404 [00:52<00:10,  8.06it/s]\u001b[0m\n",
      "\u001b[34m80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 323/404 [00:53<00:10,  8.07it/s]\u001b[0m\n",
      "\u001b[34m80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 324/404 [00:53<00:09,  8.10it/s]\u001b[0m\n",
      "\u001b[34m80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 325/404 [00:53<00:09,  8.09it/s]\u001b[0m\n",
      "\u001b[34m81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 326/404 [00:53<00:09,  8.01it/s]\u001b[0m\n",
      "\u001b[34m81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 327/404 [00:53<00:09,  7.90it/s]\u001b[0m\n",
      "\u001b[34m81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 328/404 [00:53<00:09,  8.00it/s]\u001b[0m\n",
      "\u001b[34m81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 329/404 [00:53<00:09,  7.90it/s]\u001b[0m\n",
      "\u001b[34m82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 330/404 [00:53<00:09,  7.90it/s]\u001b[0m\n",
      "\u001b[34m82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 331/404 [00:54<00:09,  7.92it/s]\u001b[0m\n",
      "\u001b[34m82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 332/404 [00:54<00:08,  8.12it/s]\u001b[0m\n",
      "\u001b[34m82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 333/404 [00:54<00:08,  8.07it/s]\u001b[0m\n",
      "\u001b[34m83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 334/404 [00:54<00:08,  8.21it/s]\u001b[0m\n",
      "\u001b[34m83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 335/404 [00:54<00:08,  8.30it/s]\u001b[0m\n",
      "\u001b[34m83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 336/404 [00:54<00:08,  8.35it/s]\u001b[0m\n",
      "\u001b[34m83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 337/404 [00:54<00:07,  8.41it/s]\u001b[0m\n",
      "\u001b[34m84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 338/404 [00:54<00:07,  8.36it/s]\u001b[0m\n",
      "\u001b[34m84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 339/404 [00:54<00:07,  8.33it/s]\u001b[0m\n",
      "\u001b[34m84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 340/404 [00:55<00:07,  8.35it/s]\u001b[0m\n",
      "\u001b[34m84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 341/404 [00:55<00:07,  8.35it/s]\u001b[0m\n",
      "\u001b[34m85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 342/404 [00:55<00:07,  8.38it/s]\u001b[0m\n",
      "\u001b[34m85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 343/404 [00:55<00:07,  8.38it/s]\u001b[0m\n",
      "\u001b[34m85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 344/404 [00:55<00:07,  8.39it/s]\u001b[0m\n",
      "\u001b[34m85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 345/404 [00:55<00:07,  8.41it/s]\u001b[0m\n",
      "\u001b[34m86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 346/404 [00:55<00:06,  8.39it/s]\u001b[0m\n",
      "\u001b[34m86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 347/404 [00:55<00:06,  8.45it/s]\u001b[0m\n",
      "\u001b[34m86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 348/404 [00:56<00:06,  8.17it/s]\u001b[0m\n",
      "\u001b[34m86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 349/404 [00:56<00:06,  8.14it/s]\u001b[0m\n",
      "\u001b[34m87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 350/404 [00:56<00:06,  8.07it/s]\u001b[0m\n",
      "\u001b[34m87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 351/404 [00:56<00:06,  8.09it/s]\u001b[0m\n",
      "\u001b[34m87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 352/404 [00:56<00:06,  7.98it/s]\u001b[0m\n",
      "\u001b[34m87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 353/404 [00:56<00:06,  8.06it/s]\u001b[0m\n",
      "\u001b[34m88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 354/404 [00:56<00:06,  8.19it/s]\u001b[0m\n",
      "\u001b[34m88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 355/404 [00:56<00:06,  8.15it/s]\u001b[0m\n",
      "\u001b[34m88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 356/404 [00:57<00:05,  8.21it/s]\u001b[0m\n",
      "\u001b[34m88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 357/404 [00:57<00:05,  8.28it/s]\u001b[0m\n",
      "\u001b[34m89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 358/404 [00:57<00:05,  8.31it/s]\u001b[0m\n",
      "\u001b[34m89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 359/404 [00:57<00:05,  8.35it/s]\u001b[0m\n",
      "\u001b[34m89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 360/404 [00:57<00:05,  8.39it/s]\u001b[0m\n",
      "\u001b[34m89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 361/404 [00:57<00:05,  8.39it/s]\u001b[0m\n",
      "\u001b[34m90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 362/404 [00:57<00:04,  8.45it/s]\u001b[0m\n",
      "\u001b[34m90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 363/404 [00:57<00:04,  8.48it/s]\u001b[0m\n",
      "\u001b[34m90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 364/404 [00:58<00:04,  8.51it/s]\u001b[0m\n",
      "\u001b[34m90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 365/404 [00:58<00:04,  8.29it/s]\u001b[0m\n",
      "\u001b[34m91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 366/404 [00:58<00:04,  8.17it/s]\u001b[0m\n",
      "\u001b[34m91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 367/404 [00:58<00:04,  8.28it/s]\u001b[0m\n",
      "\u001b[34m91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 368/404 [00:58<00:04,  8.19it/s]\u001b[0m\n",
      "\u001b[34m91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 369/404 [00:58<00:04,  8.04it/s]\u001b[0m\n",
      "\u001b[34m92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 370/404 [00:58<00:04,  7.89it/s]\u001b[0m\n",
      "\u001b[34m92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 371/404 [00:58<00:04,  7.97it/s]\u001b[0m\n",
      "\u001b[34m92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 372/404 [00:59<00:03,  8.13it/s]\u001b[0m\n",
      "\u001b[34m92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 373/404 [00:59<00:03,  8.15it/s]\u001b[0m\n",
      "\u001b[34m93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 374/404 [00:59<00:03,  8.20it/s]\u001b[0m\n",
      "\u001b[34m93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 375/404 [00:59<00:03,  8.27it/s]\u001b[0m\n",
      "\u001b[34m93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 376/404 [00:59<00:03,  8.30it/s]\u001b[0m\n",
      "\u001b[34m93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 377/404 [00:59<00:03,  8.29it/s]\u001b[0m\n",
      "\u001b[34m94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 378/404 [00:59<00:03,  8.17it/s]\u001b[0m\n",
      "\u001b[34m94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 379/404 [00:59<00:03,  8.26it/s]\u001b[0m\n",
      "\u001b[34m94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 380/404 [00:59<00:02,  8.20it/s]\u001b[0m\n",
      "\u001b[34m94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 381/404 [01:00<00:02,  8.29it/s]\u001b[0m\n",
      "\u001b[34m95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 382/404 [01:00<00:02,  8.28it/s]\u001b[0m\n",
      "\u001b[34m95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 383/404 [01:00<00:02,  8.31it/s]\u001b[0m\n",
      "\u001b[34m95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 384/404 [01:00<00:02,  8.32it/s]\u001b[0m\n",
      "\u001b[34m95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 385/404 [01:00<00:02,  8.18it/s]\u001b[0m\n",
      "\u001b[34m96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 386/404 [01:00<00:02,  8.14it/s]\u001b[0m\n",
      "\u001b[34m96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 387/404 [01:00<00:02,  8.14it/s]\u001b[0m\n",
      "\u001b[34m96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 388/404 [01:00<00:01,  8.10it/s]\u001b[0m\n",
      "\u001b[34m96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 389/404 [01:01<00:01,  7.98it/s]\u001b[0m\n",
      "\u001b[34m97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 390/404 [01:01<00:01,  7.99it/s]\u001b[0m\n",
      "\u001b[34m97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 391/404 [01:01<00:01,  8.08it/s]\u001b[0m\n",
      "\u001b[34m97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 392/404 [01:01<00:01,  8.20it/s]\u001b[0m\n",
      "\u001b[34m97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 393/404 [01:01<00:01,  8.19it/s]\u001b[0m\n",
      "\u001b[34m98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 394/404 [01:01<00:01,  8.05it/s]\u001b[0m\n",
      "\u001b[34m98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 395/404 [01:01<00:01,  8.02it/s]\u001b[0m\n",
      "\u001b[34m98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 396/404 [01:01<00:00,  8.06it/s]\u001b[0m\n",
      "\u001b[34m98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 397/404 [01:02<00:00,  8.14it/s]\u001b[0m\n",
      "\u001b[34m99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 398/404 [01:02<00:00,  8.08it/s]\u001b[0m\n",
      "\u001b[34m99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 399/404 [01:02<00:00,  8.03it/s]\u001b[0m\n",
      "\u001b[34m99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 400/404 [01:02<00:00,  7.87it/s]\u001b[0m\n",
      "\u001b[34m99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 401/404 [01:02<00:00,  7.97it/s]\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 402/404 [01:02<00:00,  7.92it/s]\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 403/404 [01:02<00:00,  7.86it/s]\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 404/404 [01:02<00:00,  7.84it/s]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.3083115816116333, 'eval_accuracy': 0.8931297709923665, 'eval_runtime': 2.4659, 'eval_samples_per_second': 53.124, 'eval_steps_per_second': 1.217, 'epoch': 4.0}\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 404/404 [01:05<00:00,  7.84it/s]\u001b[0m\n",
      "\u001b[34m#015100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-404\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-404\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-404/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-404/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-404/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-404/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /opt/ml/model/checkpoint-404 (score: 0.8931297709923665).\u001b[0m\n",
      "\u001b[34mLoading best model from /opt/ml/model/checkpoint-404 (score: 0.8931297709923665).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 67.1285, 'train_samples_per_second': 18.055, 'train_steps_per_second': 6.018, 'train_loss': 0.8916276233031017, 'epoch': 4.0}\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 404/404 [01:07<00:00,  7.84it/s]\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 404/404 [01:07<00:00,  6.02it/s]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 131\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.67it/s]\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m2024-01-08 13:32:52,032 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-01-08 13:32:52,032 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-01-08 13:32:52,032 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-01-08 13:32:59 Uploading - Uploading generated training model\n",
      "2024-01-08 13:34:00 Completed - Training job completed\n",
      "Training seconds: 387\n",
      "Billable seconds: 387\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed32b38-6039-4e53-b458-de9fc3fe66f0",
   "metadata": {},
   "source": [
    "# æ¨¡å‹éƒ¨ç½²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63a9ee08-d8b6-46a5-9163-601167af345a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env={'HF_TASK':'image-classification'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9cb3492-2a8b-441c-af65-35bab57c2c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-us-west-2-051995725733/huggingface-pytorch-training-2024-01-08-13-26-03-732/output/model.tar.gz\",  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.26\",                           # Transformers version used\n",
    "   pytorch_version=\"1.13\",                                # PyTorch version used\n",
    "   py_version='py39',                                    # Python version used\n",
    "   env=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb65f5eb-b2f4-4f72-be58-b36c523c23f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2024-01-09-02-39-21-968\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-inference-2024-01-09-02-39-22-610\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-inference-2024-01-09-02-39-22-610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839667c2-8ef6-4a04-98d5-b226d9c0df15",
   "metadata": {},
   "source": [
    "# æ¨¡å‹æ•ˆæœæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48f423fb-d237-44f7-a790-b3fe00245d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8575611114501953, 'label': 'full'},\n",
       " {'score': 0.04050292819738388, 'label': 'upper'},\n",
       " {'score': 0.03603997081518173, 'label': 'lower'},\n",
       " {'score': 0.0340271033346653, 'label': 'nohead'},\n",
       " {'score': 0.03186880424618721, 'label': 'noperson'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.serializers import DataSerializer\n",
    "\t\n",
    "predictor.serializer = DataSerializer(content_type='image/x-image')\n",
    "\n",
    "# Make sure the input file \"cats.jpg\" exists\n",
    "with open(\"./test/1702467048348.jpg\", \"rb\") as f:\n",
    "\tdata = f.read()\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c40a0208-f559-4187-bbcb-56af8457ab63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-inference-2024-01-08-13-50-14-779\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-inference-2024-01-08-13-50-14-779\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c4eb6-9e9c-47b0-b2ff-7b98d2dff5df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
